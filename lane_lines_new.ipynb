{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "import glob\n",
    "# %matplotlib qt\n",
    "import os\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing calibration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from support_files import cal_and_undistort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sraight images and curved images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "straight_images=glob.glob('test_images/straight_lines*.jpg')\n",
    "curved_images=glob.glob('test_images/test*.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibrating Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ret, mtx, dist, rvecs, tvecs = cal_and_undistort.calib(os.path.join('camera_cal','*jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mtx=np.array([[  2.62633388e+03,   0.00000000e+00,   6.53633687e+02],\n",
    "       [  0.00000000e+00,   3.09765919e+03,   3.31295828e+02],\n",
    "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00]])\n",
    "\n",
    "dist=np.array([[ -2.37078716e+00,   3.99793678e+01,   2.16836492e-02,\n",
    "         -1.09082278e-02,  -4.97428018e+02]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undistorting Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image=straight_images[0]\n",
    "image=mpimg.imread(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "undist_image=cal_and_undistort.undistort(image,mtx,dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11ddf7f98>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(undist_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient & Color Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from support_files.thresholding import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thresh_image=gradient_color_thresh(undist_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11d919908>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(thresh_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def abs_sobel_thresh(image,orient,  thresh=(20, 100)):\n",
    "    gray=cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
    "    if orient=='x':\n",
    "        sobelx=cv2.Sobel(gray,cv2.CV_64F,1,0)\n",
    "        sobelx=np.absolute(sobelx)\n",
    "        scaled_sobel=np.uint8(255*sobelx/np.max(sobelx))\n",
    "        sx_binary=np.zeros_like(scaled_sobel)\n",
    "        sx_binary[(scaled_sobel>=thresh[0]) & (scaled_sobel<=thresh[1])]=1\n",
    "        binary_output=np.copy(sx_binary)\n",
    "    if orient=='y':\n",
    "        sobely=cv2.Sobel(gray,cv2.CV_64F,0,1)\n",
    "        sobely=np.absolute(sobely)\n",
    "        scaled_sobel=np.uint8(255*sobely/np.max(sobely))\n",
    "        sx_binary=np.zeros_like(scaled_sobel)\n",
    "        sx_binary[(scaled_sobel>=thresh[0]) & (scaled_sobel<=thresh[1])]=1\n",
    "        binary_output=np.copy(sx_binary)\n",
    "    return binary_output\n",
    "\n",
    "\n",
    "def mag_thresh(img, mag_thresh=(20,150)):\n",
    "    \n",
    "    # Apply the following steps to img\n",
    "    gray=cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "    sobelx=cv2.Sobel(gray,cv2.CV_64F,1,0)\n",
    "    sobely=cv2.Sobel(gray,cv2.CV_64F,0,1)\n",
    "    sobel=np.sqrt(np.square(sobelx)+np.square(sobely))\n",
    "    scaled_sobel=np.uint8(255*sobel/np.max(sobel))\n",
    "    \n",
    "    t=sum((i > 150) &(i<200)  for i in scaled_sobel)\n",
    "#     print(np.sum(t))\n",
    "#     print(scaled_sobel.shape)\n",
    "    binary_sobel=np.zeros_like(scaled_sobel)\n",
    "    binary_sobel[(scaled_sobel>=mag_thresh[0]) & (scaled_sobel<=mag_thresh[1])]=1\n",
    "#     print(mag_thresh[0],mag_thresh[1])\n",
    "#     binary_sobel[(scaled_sobel>=20) & (scaled_sobel<=150)]=1\n",
    "#     plt.imshow(binary_sobel)\n",
    "#     plt.show()\n",
    "    return binary_sobel\n",
    "\n",
    "def dir_threshold(img,  thresh=(0.7,1.3)):\n",
    "    gray=cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "    sobelx=np.absolute(cv2.Sobel(gray,cv2.CV_64F,1,0))\n",
    "    sobely=np.absolute(cv2.Sobel(gray,cv2.CV_64F,0,1))\n",
    "    dir_=np.arctan2(sobely,sobelx)\n",
    "    sx_binary = np.zeros_like(gray)\n",
    "#     print(thresh[0],thresh[1])\n",
    "    sx_binary[(dir_>=thresh[0]) &(dir_<=thresh[1])]=1\n",
    "    binary_output=sx_binary\n",
    "    return binary_output\n",
    "\n",
    "def color_space(image,thresh=(170,255)):\n",
    "    hls=cv2.cvtColor(image,cv2.COLOR_RGB2HLS)\n",
    "    gray_image=cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
    "    l_channel=hls[:,:,1]\n",
    "    s_channel=hls[:,:,2]\n",
    "    s_binary=np.zeros_like(s_channel)\n",
    "    \n",
    "    _, gray_binary = cv2.threshold(gray_image.astype('uint8'), 150, 255, cv2.THRESH_BINARY)\n",
    "    s_binary[(s_channel>=thresh[0]) & (s_channel<=thresh[1])&(l_channel>=80)]=1\n",
    "    color_output=np.copy(s_binary)\n",
    "    return color_output\n",
    "\n",
    "def segregate_white_line(image,thresh=(200,255)):\n",
    "    hls=cv2.cvtColor(image,cv2.COLOR_RGB2HLS)\n",
    "    l_channel=hls[:,:,1]\n",
    "    l_binary=np.zeros_like(l_channel)\n",
    "    l_binary[((l_channel>=200)&(l_channel<=255))]=1\n",
    "    return l_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to call gradient and color thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_color_thresh(image):\n",
    "    ksize=3\n",
    "    image=undistort(image)\n",
    "    gradx = abs_sobel_thresh(image, orient='x', thresh=(20, 200))\n",
    "    grady = abs_sobel_thresh(image, orient='y', thresh=(20, 200))\n",
    "    # plt.imshow(gradx)\n",
    "    # plt.show()\n",
    "    # plt.imshow(grady)\n",
    "    # plt.show()\n",
    "    mag_binary = mag_thresh(image, mag_thresh=(20, 200))\n",
    "    # plt.imshow(mag_binary)\n",
    "    # plt.show()\n",
    "\n",
    "    dir_binary = dir_threshold(image, thresh=(0.7, 1.3))\n",
    "    color_binary=color_space(image,thresh=(100,255))\n",
    "    \n",
    "    combined = np.zeros_like(dir_binary)\n",
    "    # combined[((gradx == 1)& (grady == 1)) |(color_binary==1)] = 1\n",
    "    combined[(color_binary==1)|((gradx == 1)& (grady == 1)) |(mag_binary==1) &(dir_binary==1)] = 1\n",
    "#     plt.imshow(combined)\n",
    "#     plt.show()\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    morph_image=combined[600:,:950]\n",
    "    # morph_image = cv2.morphologyEx(morph_image, cv2.MORPH_CLOSE, kernel)\n",
    "    morph_image = cv2.morphologyEx(morph_image, cv2.MORPH_OPEN, kernel)\n",
    "    # morph_image=cv2.erode(morph_image,kernel,iterations = 1)\n",
    "    combined[600:,:950]=morph_image\n",
    "    white_line=segregate_white_line(image,thresh=(200,255))\n",
    "    combined=(combined)|(white_line)\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perspective Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perspective_transform(image):\n",
    "    src=np.float32([[195,720],[590,460],[700,460],[1120,720]])\n",
    "    dst=np.float32([[350,720],[410,0],[970,0],[1000,720]])\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    img_size=(image.shape[1],image.shape[0])\n",
    "    print(M.shape,Minv.shape)\n",
    "    warped = cv2.warpPerspective(image, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    return warped,Minv,M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3) (3, 3)\n"
     ]
    }
   ],
   "source": [
    "binary_warped,Minv,M=perspective_transform(thresh_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11daa1630>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(binary_warped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline to detect lanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pipeline(binary_warped,count,image):\n",
    "    if count==0:\n",
    "        # Assuming you have created a warped binary image called \"binary_warped\"\n",
    "        # Take a histogram of the bottom half of the image\n",
    "        histogram = np.sum(binary_warped[int(binary_warped.shape[0]/2):,:], axis=0)\n",
    "        # Create an output image to draw on and  visualize the result\n",
    "        out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "        # Find the peak of the left and right halves of the histogram\n",
    "        # These will be the starting point for the left and right lines\n",
    "        midpoint = np.int(histogram.shape[0]/2)\n",
    "        leftx_base = np.argmax(histogram[:midpoint])\n",
    "        rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "        # Choose the number of sliding windows\n",
    "        nwindows = 9\n",
    "        # Set height of windows\n",
    "        window_height = np.int(binary_warped.shape[0]/nwindows)\n",
    "        # Identify the x and y positions of all nonzero pixels in the image\n",
    "        nonzero = binary_warped.nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Current positions to be updated for each window\n",
    "        leftx_current = leftx_base\n",
    "        rightx_current = rightx_base\n",
    "        # Set the width of the windows +/- margin\n",
    "        margin = 100\n",
    "        # Set minimum number of pixels found to recenter window\n",
    "        minpix = 50\n",
    "        # Create empty lists to receive left and right lane pixel indices\n",
    "        left_lane_inds = []\n",
    "        right_lane_inds = []\n",
    "\n",
    "        # Step through the windows one by one\n",
    "        for window in range(nwindows):\n",
    "            # Identify window boundaries in x and y (and right and left)\n",
    "            win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "            win_y_high = binary_warped.shape[0] - window*window_height\n",
    "            win_xleft_low = leftx_current - margin\n",
    "            win_xleft_high = leftx_current + margin\n",
    "            win_xright_low = rightx_current - margin\n",
    "            win_xright_high = rightx_current + margin\n",
    "            # Draw the windows on the visualization image\n",
    "            cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),\n",
    "            (0,255,0), 2) \n",
    "            cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),\n",
    "            (0,255,0), 2) \n",
    "            # Identify the nonzero pixels in x and y within the window\n",
    "            good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "            (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "            good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "            (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "            # Append these indices to the lists\n",
    "            left_lane_inds.append(good_left_inds)\n",
    "            right_lane_inds.append(good_right_inds)\n",
    "            # If you found > minpix pixels, recenter next window on their mean position\n",
    "            if len(good_left_inds) > minpix:\n",
    "                leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "            if len(good_right_inds) > minpix:        \n",
    "                rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "        # Concatenate the arrays of indices\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "        # Extract left and right line pixel positions\n",
    "        leftx = nonzerox[left_lane_inds]\n",
    "        lefty = nonzeroy[left_lane_inds] \n",
    "        rightx = nonzerox[right_lane_inds]\n",
    "        righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "        # Fit a second order polynomial to each\n",
    "        left_fit = np.polyfit(lefty, leftx, 2)\n",
    "        right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "        ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "        warp_zero = np.zeros_like(binary_warped).astype(np.uint8)\n",
    "        color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "        # Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "        # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "        pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "        pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "        pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "        # Draw the lane onto the warped blank image\n",
    "        cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "        # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "        newwarp = cv2.warpPerspective(color_warp, Minv, (image.shape[1], image.shape[0])) \n",
    "        # Combine the result with the original image\n",
    "        result = cv2.addWeighted(image, 1, newwarp, 0.3, 0)\n",
    "        \n",
    "        y_eval=700\n",
    "        mid_x=640\n",
    "        ym_per_pix=3.0/72.0\n",
    "        xm_per_pix=3.7/650.0 #HardCoded\n",
    "        \n",
    "        c1=(2*right_fit[0]*y_eval+right_fit[1])*xm_per_pix/ym_per_pix\n",
    "        c2=2*right_fit[0]*xm_per_pix/(ym_per_pix**2)\n",
    "        \n",
    "        curvature=((1+c1*c1)**1.5)/(np.absolute(c2))\n",
    "        \n",
    "        left_pos=(left_fit[0]*(y_eval**2))+(left_fit[1]*y_eval)+left_fit[2]\n",
    "        right_pos=(right_fit[0]*(y_eval**2))+(right_fit[1]*y_eval)+right_fit[2]\n",
    "        \n",
    "        dx=((left_pos+right_pos)/2-mid_x)*xm_per_pix\n",
    "        if dx>0:\n",
    "            text='Right'\n",
    "        else:\n",
    "            text='Left'\n",
    "        \n",
    "        font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(result,'Radius of curvature  = %.2f m'%(curvature),(20,50), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "        \n",
    "        cv2.putText(result,'Vehicle position : %.2f m %s of center'%(abs(dx), text),(20,90),\n",
    "                        font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "        \n",
    "        return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result=pipeline(binary_warped,count,image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x124d4b438>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of support_files.pipeline failed: Traceback (most recent call last):\n",
      "  File \"/Users/samkitjain/anaconda/envs/python35/lib/python3.5/site-packages/IPython/extensions/autoreload.py\", line 246, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/samkitjain/anaconda/envs/python35/lib/python3.5/site-packages/IPython/extensions/autoreload.py\", line 385, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/Users/samkitjain/anaconda/envs/python35/lib/python3.5/site-packages/IPython/extensions/autoreload.py\", line 324, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/Users/samkitjain/anaconda/envs/python35/lib/python3.5/site-packages/IPython/extensions/autoreload.py\", line 279, in update_class\n",
      "    if old_obj == new_obj:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from support_files.pipeline import pipeline\n",
    "from support_files.draw_line import line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video project_videos_output/new_result_video.mp4\n",
      "[MoviePy] Writing video project_videos_output/new_result_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1261 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/1261 [00:00<08:41,  2.42it/s]\u001b[A\n",
      "  0%|          | 2/1261 [00:00<08:42,  2.41it/s]\u001b[A\n",
      "  0%|          | 3/1261 [00:01<08:26,  2.48it/s]\u001b[A\n",
      "  0%|          | 4/1261 [00:01<08:25,  2.49it/s]\u001b[A\n",
      "100%|█████████▉| 1260/1261 [07:13<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: project_videos_output/new_result_video.mp4 \n",
      "\n",
      "CPU times: user 9min 54s, sys: 1min 30s, total: 11min 24s\n",
      "Wall time: 7min 15s\n"
     ]
    }
   ],
   "source": [
    "line_=line()\n",
    "pipeline.set_vals(line_,mtx,dist,M,Minv)\n",
    "video_output = 'project_videos_output/new_result_video.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "video_clip = clip1.fl_image(pipeline.Pipeline)\n",
    "%time video_clip.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video project_videos_output/new_result_challenge_video.mp4\n",
      "[MoviePy] Writing video project_videos_output/new_result_challenge_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 485/485 [02:37<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: project_videos_output/new_result_challenge_video.mp4 \n",
      "\n",
      "CPU times: user 3min 48s, sys: 32.5 s, total: 4min 20s\n",
      "Wall time: 2min 39s\n"
     ]
    }
   ],
   "source": [
    "line_=line()\n",
    "pipeline.set_vals(line_,mtx,dist,M,Minv)\n",
    "video_output = 'project_videos_output/new_result_challenge_video.mp4'\n",
    "clip1 = VideoFileClip(\"challenge_video.mp4\")\n",
    "video_clip = clip1.fl_image(pipeline.Pipeline)\n",
    "%time video_clip.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video project_videos_output/new_result_harder_challenge_video.mp4\n",
      "[MoviePy] Writing video project_videos_output/new_result_harder_challenge_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1199/1200 [07:52<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: project_videos_output/new_result_harder_challenge_video.mp4 \n",
      "\n",
      "CPU times: user 10min 6s, sys: 1min 39s, total: 11min 46s\n",
      "Wall time: 7min 55s\n"
     ]
    }
   ],
   "source": [
    "line_=line()\n",
    "pipeline.set_vals(line_,mtx,dist,M,Minv)\n",
    "video_output = 'project_videos_output/new_result_harder_challenge_video.mp4'\n",
    "clip1 = VideoFileClip(\"harder_challenge_video.mp4\")\n",
    "video_clip = clip1.fl_image(pipeline.Pipeline)\n",
    "%time video_clip.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    undist_image=undistort(image)\n",
    "#     gray_image=cv2.cvtColor(undist_image,cv2.COLOR_RGB2GRAY)\n",
    "    thresh_image=gradient_color_thresh(undist_image)\n",
    "    warped,Minv=perspective_transform(thresh_image)\n",
    "    result=pipeline(warped,undist_image,left_fit,right_fit,count,Minv)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
